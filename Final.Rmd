
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<center>
<B><font size="5">Credit Card Fraud Detection
<BR>Final Project Report</font>
<BR><font size="4">Instructor: Samantha-Jo Caetano
<BR><I>Yuhan Zhu</I>
<BR>Github Link:https://github.com/juliaz1231/final-proj.git
<BR>Date: 12/22/2020</I></font></B></center>

<P>
<B><font size="4">Abstract</font></B>
<BR>In this project, a predictive model has been produced for credit card fraud detections. The accuracy score for the model is high enough for using. The reason to predict credit card fraud activities is to secure people's property and money.By doing so, banks can gain more trust from people.
<P>
<B><font size="4">KeyWord</font></B>
<BR>Data Cleaning, Credit Card Fraud Detection, Predictive Model, Logistic Regression, Linear Regression,Accuracy Score, Precision-Recall Curve
<P>
<B><font size="4">Introduction</font></B>
<BR>Big data has occupied almost the entire market in every industry, including credit card companies. They use predictive analysis to detect transactions that contain potential risks. According to the government of the United States, Credit card fraud is defined as “an unauthorized use of a credit or debit card, or similar tool, to fraudulently obtain money or property.” Recognizing fraud transactions can prevent customers from charging items they did not purchased.

According to the Federal Reserve Payments study,  26.2 Billion purchases in 2012 were made by US citizens’ credit card usage, with a  total value of $6.1 billion unauthorized transactions. In order to prevent the loss of dollars, credit cards, eCommerce companies and banks have decided to use big data to solve their problems. 

After including big data technology into the system, credit card companies were able to detect credit card fraud transactions successfully. Algorithms can produce a possibility of fraud activities by analyzing an user’s habit, location, currency and other attributes. The credit card will be declined if there is a suspicious transaction.

In this project, one dataset will be used to produce a predictive analysis for potential credit card fraud. In the Methodology section. I will describe the data, and the model that was used to perform the analysis. Results of the analysis are provided in the Results section and inferences of this data along with conclusions are presented in the Conclusion section. section.

<P>
<B><font size="4">Data and Methodology</font></B>
<P>
<B><font size="3">Data:</font></B>
The dataset is collected by a research collaboration of Worldline and the Machine Learning Group of ULB on big data mining and fraud detection. It contains only numerical input variables and they are results of PCA transformation. Features V1,V2,V3,...,V28 are obtained with PCA. "Time" and "Amount" have not been transformed."Class" represents the response variable and "1" means fraud, "0" means not fraud.
<P>
<B><font size="3">Model:</font></B>
An exploratory data analysis is conducted first.Data preprocessing is important for furthur analysis, such as removing missing values or outliers.In order to understand the relationships among attributes easier, a corrplot is conducted because it is a graphical representation of data that allows people understanding the dataset easier by looking at it.

In order to build a predictive model, understanding the type of models is important. The problem is to detect whether a transaction is fraud, so the outcome is binary  which means it should be either “Yes” or “No”. Logistic regression will be applied in the project because When the dependent variable is binary, it is appropriate to apply logistic regression analysis. 

Lastly, a Hosmer-Lemeshow Test is conducted to test for logistic regression. It is a goodness of fit test and it is especially good for logistic regression.

<P>
<B><font size="4">Results</font></B>
<P>
<B><font size="3">Exploratory Data Analysis:</font></B>
<P>During the process of EDA, I first imported the dataset and named it as "df". Here is the head of the dataset:<P>
![Figure 1](C:/Users/12069/Desktop/hxn/head.png)

<P>There are total of 284807 observations of 31 variables. There is 0 missing values. Because the time and the amount have not been transformed. For better model performance, I removed the time variable and changed the "amount" variable by using scale() function. The new dataset was named as "df2" and it contains 284807 observations of 30 variables.<P>
```{r,include=FALSE}
library(tidyverse)
library(lattice)
library(grid)
library(pROC)
library(corrplot)
library(caTools)
library(ggplot2)
library(ResourceSelection)
df <- read.csv("C:/Users/12069/Desktop/hxn/creditcard.csv")
```
<P>The total numbers of "0"s in the dataset is 284315 and the total number of "1"s is 492. Here is a barplot for both classes:<P>
<P>![Figure 2](C:/Users/12069/Desktop/hxn/counts.png)

```{r,include=FALSE}
dim(df)
sum(is.na(df))
```
```{r,include=FALSE}
df$Amount <- scale(df$Amount)
df2 <- df[,-c(1)]
table(df$Class)
```
```{r,include=FALSE}
barplot(table(df2$Class),  main = "Total Counts of Classes",  
        ylab = "COUNTS",cex.names=0.6,cex.axis=1, las=1,
        ylim = c(0,max(table(df$Class))),names.arg=as.data.frame(table(df$Class))$Var1,
        col = c("red",'yellow')
)
```
<P>The next step is to find correlations among variables. A correplot was conducted by using "corrplot" function. It plots all the attributes and the plot is shown below:<P>
<P>![Figure 3](C:/Users/12069/Desktop/hxn/heatmap.png)

<P>From the plot, I found that it is hard to tell if the correlation between variables.<P>
```{r,include=FALSE}
correlations <- cor(df,method="pearson")
corrplot(correlations, number.cex = .9, method = "square", type = "full", tl.cex=0.8,tl.col = "pink")
```
<P>
<B><font size="3">Predictive analysis:</font></B>
<P>Now the data has been preprocessed. It is time to build a good predictive model.
First step is to create the train and test dataset.I splitted the origional dataset by using ratio 7:3. So 70% of the dataset is training set, and 30% of the dataset is testing set.Then I generated a logistic regression model by using glm(Class~., train, family = binomial(link = "logit")). In this function, Class was the reponse variable and the rest are independent variable. Here is a summary for the model:<P>
<P>![Figure 4](C:/Users/12069/Desktop/hxn/logisticregressionsummary.png)

<P>Then I plotted the model and here are four plots:<P>
<P>![Figure 5](C:/Users/12069/Desktop/hxn/residvsfits.png)

<P>In the "Residuals vs fitted" plot, there are three out liers with large residual values.THe red line and the dashed line are almost perfectly attached.<P>
<P>![Figure 6](C:/Users/12069/Desktop/hxn/qqnorm.png)

<P>In the Normal Q-Q plot, it clearly shows that the distribution is not normal because it is heavily tailed at each end.<P>
<P>![Figure 7](C:/Users/12069/Desktop/hxn/scalelotion.png)

<P>In the scale-location plot, the red line fits the dots pretty well and it is roughly horizontal, which indicates the spread of residuals is roughly equal at all fitted values.<P>
<P>![Figure 8](C:/Users/12069/Desktop/hxn/resivslev.png)

<P>By looking at the residuals vs leverage plot, it is unclear to see any information because of outliers.

```{r,include=FALSE}
set.seed(111)
sample <- sample.split(df2$Class, SplitRatio = 0.70)
train <- subset(df2,sample == TRUE)
test <- subset(df2,sample == FALSE)
dim(train)
dim(test)
```
<P>After creating the logistic regression model, I used it to predict y values by using testing set and named the predicted values as "predict".Here is the table of predicted value and test value:
<P>![Figure 9](C:/Users/12069/Desktop/hxn/table.png)

<P>I then calculated the RMSE value, which stands for root-mean-square-error. Here is its formula:
<P>![Figure 10](C:/Users/12069/Desktop/hxn/frmula.png)

<P>The value I got is 5.64486934348491. The model accuracy is 0.999040295869761 and the error rate of the model is 0.00107674121929239.I also created an ROC curve for the logistic regression model.ROC curve indicates the performance of a classfication model.Specificity stands for False positive rate, and sensitivity stands for true positive rate.
<P>![Figure 11](C:/Users/12069/Desktop/hxn/roccurve.png)

<P>![Figure 12](C:/Users/12069/Desktop/hxn/printcurve.png)

```{r,include=FALSE}
logistic_regression_model = glm(Class~., train, family = binomial(link = "logit"))
summary(logistic_regression_model)
plot(logistic_regression_model)

predict <- predict(logistic_regression_model,test,type = "response")
predict <- ifelse(predict > 0.5,1,0)

rmse <- sqrt(sum((test-predict)^2)/85443)
print(paste("Root Mean Sqaure Error:",rmse))

auc.gbm = roc(test$Class,predict,plot=T, col = "blue")
print(auc.gbm)
table(test$Class, predict)

misClasificError <- mean(predict != test$Class)
print(paste('Accuracy:',1-misClasificError))

print(paste('Error rate of model:',mean((predict & test$Class==0) | (predict & test$Class==1))))

```
<P>The area under the curve, which is AUC, is 0.7668 and it shows an acceptable result.
<P>I also used Hosmer-Lemeshow test to do a goodness of fit test for the logistic model I produced and then I ggplot the test.Here are the GOF table and ggplot:
<P>![Figure 13](C:/Users/12069/Desktop/hxn/GOODFITDATA.png)

<P>![Figure 14](C:/Users/12069/Desktop/hxn/GOODFITPLOT.png)

<P>By looking at the GOF test table, the p value is 0.1166.
```{r,include=FALSE}
hosmer_t <- hoslem.test(logistic_regression_model$y, fitted(logistic_regression_model))
hosmer_t

hosmer_t_df <- data.frame(observed=hosmer_t$observed[,2], expected=hosmer_t$expected[,2])
ggplot(hosmer_t_df, aes(x=observed, y=expected)) +
  geom_point() +
  geom_smooth() +
  geom_abline(intercept=0, slope=1, size=0.5)

```
<P>
<B><font size="4">Discussions</font></B>
<BR>Here I have finished displaying the exploratory analysis which also inclusing data preprocessing, predictive analysis and goodess-of-fit that shows the performance of the model.

There is a few findings after conducing an exploratory analysis. There is no missing values in the dataset.All the variables are numeric variables. There is a very small amount of "1" comparing to "0" which causes an imbalanced dependent variable. Howeverf, it also indicates a good sign that there is only a small portion of fraud transacstions for all the credit card activities.

After finishing data preprocessing, a logistic model was produced. The RMSE is 5.64486934348491, the model accuracy is 0.999040295869761 and the error rate of the model is 0.00107674121929239. These three numbers are indicating the error between predicted and tested values is relatively small and the accuracy of the model is relatively high. The ROC and AUC also showed the model is relatively good. I also used Hosmer-Lemeshow test to do a goodess-of-fit test for the logistic regression model I created. The p value is 0.1166, which is larger than the significant level 0.05. It indicates that this logistic regression model is a good model. 

The weakness of the analysis is the lack of comparisons between models. Due to the lack of knowledge I have learned about big data, I didn't know what other models are good for a binary dataset. I have tried usng linear regression, postStratification; however, they both didn't work well and console kept getting errors. so I removed them in the coding process.

In the future, I would like to apply decision tree, random forest and other popular classification models for this project. I have browsed online and these algorithms are good for classification datasets.By comparing different models, I could choose the best one to be my final result.

<P>
<B><font size="4">References</font></B>
<P>Credit Card Fraud. (2016, June 15). Retrieved December 16, 2020, from https://www.fbi.gov/scams-and-safety/common-scams-and-crimes/credit-card-fraud
<P>James, R. (2020, January 15). How Is Big Data Used To Fight Against Credit Card Fraud? Retrieved December 16, 2020, from https://becominghuman.ai/how-is-big-data-used-to-fight-against-credit-card-fraud-568fd6d63387
<P>Stephanie. (2016, August 28). Hosmer-Lemeshow Test: Definition. Retrieved December 16, 2020, from https://www.statisticshowto.com/hosmer-lemeshow-test/
<P>Swaminathan, S. (2019, January 18). Logistic Regression - Detailed Overview. Retrieved December 16, 2020, from https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc
<P>ULB, M. (2018, March 23). Credit Card Fraud Detection. Retrieved December 16, 2020, from https://www.kaggle.com/mlg-ulb/creditcardfraud
<P>What is Logistic Regression? (2020, March 09). Retrieved December 16, 2020, from https://www.statisticssolutions.com/what-is-logistic-regression/